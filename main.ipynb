{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32164 entries, 0 to 32163\n",
      "Data columns (total 45 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 32164 non-null  int64  \n",
      " 1   dur                32164 non-null  float64\n",
      " 2   proto              32164 non-null  object \n",
      " 3   service            32164 non-null  object \n",
      " 4   state              32164 non-null  object \n",
      " 5   spkts              32164 non-null  int64  \n",
      " 6   dpkts              32164 non-null  int64  \n",
      " 7   sbytes             32164 non-null  int64  \n",
      " 8   dbytes             32164 non-null  int64  \n",
      " 9   rate               32164 non-null  float64\n",
      " 10  sttl               32164 non-null  int64  \n",
      " 11  dttl               32164 non-null  int64  \n",
      " 12  sload              32164 non-null  float64\n",
      " 13  dload              32164 non-null  float64\n",
      " 14  sloss              32164 non-null  int64  \n",
      " 15  dloss              32164 non-null  int64  \n",
      " 16  sinpkt             32164 non-null  float64\n",
      " 17  dinpkt             32164 non-null  float64\n",
      " 18  sjit               32164 non-null  float64\n",
      " 19  djit               32164 non-null  float64\n",
      " 20  swin               32164 non-null  int64  \n",
      " 21  stcpb              32164 non-null  int64  \n",
      " 22  dtcpb              32164 non-null  int64  \n",
      " 23  dwin               32164 non-null  int64  \n",
      " 24  tcprtt             32164 non-null  float64\n",
      " 25  synack             32164 non-null  float64\n",
      " 26  ackdat             32164 non-null  float64\n",
      " 27  smean              32164 non-null  int64  \n",
      " 28  dmean              32164 non-null  int64  \n",
      " 29  trans_depth        32164 non-null  int64  \n",
      " 30  response_body_len  32164 non-null  int64  \n",
      " 31  ct_srv_src         32164 non-null  int64  \n",
      " 32  ct_state_ttl       32164 non-null  int64  \n",
      " 33  ct_dst_ltm         32164 non-null  int64  \n",
      " 34  ct_src_dport_ltm   32164 non-null  int64  \n",
      " 35  ct_dst_sport_ltm   32164 non-null  int64  \n",
      " 36  ct_dst_src_ltm     32164 non-null  int64  \n",
      " 37  is_ftp_login       32164 non-null  int64  \n",
      " 38  ct_ftp_cmd         32164 non-null  int64  \n",
      " 39  ct_flw_http_mthd   32164 non-null  int64  \n",
      " 40  ct_src_ltm         32164 non-null  int64  \n",
      " 41  ct_srv_dst         32164 non-null  int64  \n",
      " 42  is_sm_ips_ports    32164 non-null  int64  \n",
      " 43  attack_cat         32164 non-null  object \n",
      " 44  label              32164 non-null  int64  \n",
      "dtypes: float64(11), int64(30), object(4)\n",
      "memory usage: 11.0+ MB\n",
      "None\n",
      "   id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
      "0   1  0.000011   udp       -   INT      2      0     496       0   \n",
      "1   2  0.000008   udp       -   INT      2      0    1762       0   \n",
      "2   3  0.000005   udp       -   INT      2      0    1068       0   \n",
      "3   4  0.000006   udp       -   INT      2      0     900       0   \n",
      "4   5  0.000010   udp       -   INT      2      0    2126       0   \n",
      "\n",
      "          rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
      "0   90909.0902  ...                 1               2             0   \n",
      "1  125000.0003  ...                 1               2             0   \n",
      "2  200000.0051  ...                 1               3             0   \n",
      "3  166666.6608  ...                 1               3             0   \n",
      "4  100000.0025  ...                 1               3             0   \n",
      "\n",
      "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
      "0           0                 0           1           2                0   \n",
      "1           0                 0           1           2                0   \n",
      "2           0                 0           1           3                0   \n",
      "3           0                 0           2           3                0   \n",
      "4           0                 0           2           3                0   \n",
      "\n",
      "   attack_cat  label  \n",
      "0      Normal      0  \n",
      "1      Normal      0  \n",
      "2      Normal      0  \n",
      "3      Normal      0  \n",
      "4      Normal      0  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "Assuming 'attack_cat' as target variable based on dataset structure.\n",
      "Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "url = 'UNSW_NB15_training-set.csv'  # Update this path if needed\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Display dataset info to understand its structure\n",
    "print(data.info())\n",
    "print(data.head())\n",
    "\n",
    "# Strip white spaces from column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Convert categorical features to numerical using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Let's inspect the dataset columns and update the categorical columns\n",
    "categorical_cols = ['proto', 'service', 'state']  # Adjust based on actual columns\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = label_encoder.fit_transform(data[col])\n",
    "    else:\n",
    "        print(f\"Column '{col}' not found in the dataset.\")\n",
    "\n",
    "# Now let's check if 'Label' exists or if there's another target column for classification\n",
    "if 'Label' in data.columns:\n",
    "    y = data['Label']\n",
    "else:\n",
    "    # Assuming a target column like 'attack_cat' or something relevant for classification\n",
    "    print(\"Assuming 'attack_cat' as target variable based on dataset structure.\")\n",
    "    y = data['attack_cat'] if 'attack_cat' in data.columns else None\n",
    "\n",
    "if y is None:\n",
    "    print(\"No target column found for classification.\")\n",
    "else:\n",
    "    # Drop irrelevant or identifier columns (e.g., 'id') and the target column\n",
    "    X = data.drop(['id', 'Label', 'attack_cat'], axis=1, errors='ignore')\n",
    "\n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize the numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    print(\"Preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[   0    0   24    6    0    0    0    0    0    0]\n",
      " [   0    1    2    3    0    0    0    0    0    0]\n",
      " [   0    0  257  337    1    0    0    2    4    0]\n",
      " [   0    1  304  804    2    0    0   21    6    0]\n",
      " [   0    0   41   30  144    0    0    2    0    0]\n",
      " [   0    0    2   20    1 2234    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1803    0    0    0]\n",
      " [   0    0   46   57    0    0    0  243    0    0]\n",
      " [   0    0    3    9    2    1    0    2   13    0]\n",
      " [   0    0    1    4    0    0    0    0    0    0]]\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.00      0.00      0.00        30\n",
      "      Backdoor       0.50      0.17      0.25         6\n",
      "           DoS       0.38      0.43      0.40       601\n",
      "      Exploits       0.63      0.71      0.67      1138\n",
      "       Fuzzers       0.96      0.66      0.78       217\n",
      "       Generic       1.00      0.99      0.99      2257\n",
      "        Normal       1.00      1.00      1.00      1803\n",
      "Reconnaissance       0.90      0.70      0.79       346\n",
      "     Shellcode       0.57      0.43      0.49        30\n",
      "         Worms       0.00      0.00      0.00         5\n",
      "\n",
      "      accuracy                           0.85      6433\n",
      "     macro avg       0.59      0.51      0.54      6433\n",
      "  weighted avg       0.86      0.85      0.86      6433\n",
      "\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AIML\\Projects\\Unstructured_CyberSec\\.conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\AIML\\Projects\\Unstructured_CyberSec\\.conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\AIML\\Projects\\Unstructured_CyberSec\\.conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\AIML\\Projects\\Unstructured_CyberSec\\.conda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Final Confusion Matrix:\n",
      "[[   0    0   29    1    0    0    0    0    0    0]\n",
      " [   0    0    2    4    0    0    0    0    0    0]\n",
      " [   0    0  451  144    1    0    0    5    0    0]\n",
      " [   0    0  339  782    3    0    0   13    1    0]\n",
      " [   0    0   61    9  143    0    0    4    0    0]\n",
      " [   0    0    2   22    1 2232    0    0    0    0]\n",
      " [   0    0    0    0    0    0 1803    0    0    0]\n",
      " [   0    0   55   48    0    0    0  243    0    0]\n",
      " [   0    0    1   18    0    0    0    6    5    0]\n",
      " [   0    0    0    5    0    0    0    0    0    0]]\n",
      "\n",
      "Final Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.00      0.00      0.00        30\n",
      "      Backdoor       0.00      0.00      0.00         6\n",
      "           DoS       0.48      0.75      0.59       601\n",
      "      Exploits       0.76      0.69      0.72      1138\n",
      "       Fuzzers       0.97      0.66      0.78       217\n",
      "       Generic       1.00      0.99      0.99      2257\n",
      "        Normal       1.00      1.00      1.00      1803\n",
      "Reconnaissance       0.90      0.70      0.79       346\n",
      "     Shellcode       0.83      0.17      0.28        30\n",
      "         Worms       0.00      0.00      0.00         5\n",
      "\n",
      "      accuracy                           0.88      6433\n",
      "     macro avg       0.59      0.50      0.51      6433\n",
      "  weighted avg       0.89      0.88      0.88      6433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AIML\\Projects\\Unstructured_CyberSec\\.conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\AIML\\Projects\\Unstructured_CyberSec\\.conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\AIML\\Projects\\Unstructured_CyberSec\\.conda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cybersecurity_model.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries for modeling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume 'scaler' is your StandardScaler instance used for scaling during training\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler to a file\n",
    "with open('scaler.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n",
    "# 1. Model Selection: Choosing Random Forest Classifier for demonstration\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 2. Model Training\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 3. Model Evaluation\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 4. Hyperparameter Tuning\n",
    "# Define parameters for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, \n",
    "                           scoring='f1', cv=3, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters from grid search\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# 5. Using the best model for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "best_y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Final Evaluation\n",
    "print(\"Final Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, best_y_pred))\n",
    "\n",
    "print(\"\\nFinal Classification Report:\")\n",
    "print(classification_report(y_test, best_y_pred))\n",
    "\n",
    "# 6. Save the model\n",
    "joblib.dump(best_model, 'cybersecurity_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
